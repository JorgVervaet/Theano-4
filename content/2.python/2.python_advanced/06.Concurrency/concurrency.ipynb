{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency and Parallelism in Python\n",
    "Until now, we have used Python sequentially: instructions were executed one after the other.\n",
    "\n",
    "However, Python offers in its standard library several modules for **concurrent** and **parallel** execution: several instructions of code will execute at the same time, or seem to.\n",
    "\n",
    "In Python 3, there are 3 main ways to execute code in concurrently on your local machine:\n",
    "\n",
    "|Concurrency Type | Switching Decision | Number of CPU cores|\n",
    "| --- | --- | --- |\n",
    "|Pre-emptive multitasking (threading) | The operating system decides when to switch tasks external to Python. | 1|\n",
    "|Cooperative multitasking (asyncio) | The tasks decide when to give up control. | 1|\n",
    "|Multiprocessing (multiprocessing) | The processes all run at the same time on different processors. | Many| \n",
    "\n",
    "In the scope of this course, we will not cover cooperative multitasking. Most of your needs can be covered by simple threading or multiprocessing but that should not discourage you from learning about `asyncio` as it is pretty neat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple threading example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we define a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def task(id):\n",
    "    print(f\"Task {id}: starting. \")\n",
    "    sleep(.1) # .1 seconds\n",
    "    print(f\"Task {id}: finishing. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to call it 5 times. We measure how long it will take to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0: starting. \n",
      "Task 0: finishing. \n",
      "Task 1: starting. \n",
      "Task 1: finishing. \n",
      "Task 2: starting. \n",
      "Task 2: finishing. \n",
      "Task 3: starting. \n",
      "Task 3: finishing. \n",
      "Task 4: starting. \n",
      "Task 4: finishing. \n",
      "\n",
      "Time spent inside the loop: 0.5191478950000032 seconds.\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "for i in range(5):\n",
    "    task(i)\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wait 5 times for .1 second, so .5 seconds. What if we start 5 times the `task()` method at once?\n",
    "\n",
    "We use the ``threading`` module. We create a ``Thread`` object whose contructor takes the function and its arguments as parameters. Then, we ``start()`` the thread.\n",
    "\n",
    "This executes the tasks *concurrently* on one CPU core. Picture the OS passing \"the ball\" to each thread one by one and waiting for them to send it back in their own time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0: starting. Task 1: starting. \n",
      "\n",
      "Task 2: starting. \n",
      "Task 3: starting. Task 4: starting. \n",
      "\n",
      "Task 0: finishing. \n",
      "Task 3: finishing. \n",
      "Task 4: finishing. \n",
      "Task 1: finishing. Task 2: finishing. \n",
      "\n",
      "\n",
      "Time spent inside the loop: 0.10578233299997919 seconds.\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "threads = list()\n",
    "for i in range(5):\n",
    "    thread = Thread(target=task, args=(i,)) # New thread will run \"task\" with argument \"i\"\n",
    "    threads.append(thread) # To keep track of all the treads\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:  # The second loop is necessary. start() everything then join() everything.\n",
    "    thread.join() # Make sure all the threads are done before continuing\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack what we observe:\n",
    "\n",
    "* **Evidence of concurrent execution:** \n",
    "  * The final **print()** function executes after only .1 second.\n",
    "* **Threading does not guaranty order:** \n",
    "  * The threads do *not* finish in the order they were started.\n",
    "* **Evidence of race conditions:** \n",
    "  * The outputs are mangled. \n",
    "  * Observe how some outputs are on the same line, showing a thread started to write while another was still writing.\n",
    "  * The threads are fighting for the same resource. In this case, the standard output, your screen.\n",
    "\n",
    "### Locks avoid race conditions\n",
    "\n",
    "A simple way to \"synchronize\" our threads, to share resources gracefully, we use a *lock*:\n",
    "\n",
    "When accessing a shared resource, we tell the lock to block its access until released. If another thread wants to use this resource, it must wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import RLock\n",
    "\n",
    "rlock = RLock() # Needs to be outside the function. Created once, used by every thread.\n",
    "\n",
    "def task_locked(i):\n",
    "    with rlock: # Equivalent of rlock.acquire() [insert code] rlock.release()\n",
    "        task(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0: starting. \n",
      "Task 0: finishing. \n",
      "Task 1: starting. \n",
      "Task 1: finishing. \n",
      "Task 2: starting. \n",
      "Task 2: finishing. \n",
      "Task 3: starting. \n",
      "Task 3: finishing. \n",
      "Task 4: starting. \n",
      "Task 4: finishing. \n",
      "\n",
      "Time spent inside the loop: 0.5279639750000342 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter()\n",
    "\n",
    "threads = list()\n",
    "for i in range(5):\n",
    "    thread = Thread(target=task_locked, args=(i,))\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "    \n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the lock is blocking the whole ``task()`` function. It is better to lock at a more granular level to free up the locked resources more often. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_locked(id):\n",
    "    with rlock:\n",
    "        print(f\"Task {id}: starting. \")\n",
    "    sleep(.1) # This is the part that takes time and should be run concurrently\n",
    "    with rlock:\n",
    "        print(f\"Task {id}: finishing. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0: starting. \n",
      "Task 1: starting. \n",
      "Task 2: starting. \n",
      "Task 3: starting. \n",
      "Task 4: starting. \n",
      "Task 0: finishing. \n",
      "Task 1: finishing. \n",
      "Task 2: finishing. \n",
      "Task 3: finishing. \n",
      "Task 4: finishing. \n",
      "\n",
      "Time spent inside the loop: 0.11413254100000358 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter()\n",
    "\n",
    "threads = list()\n",
    "for i in range(5):\n",
    "    thread = Thread(target=task_locked, args=(i,))\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "    \n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOP equivalent\n",
    "\n",
    "To run the code concurrently, the ``Sleeper`` class inherits from the `Thread` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sleeper(Thread): # Sleeper is a Thread\n",
    "    def __init__(self, id): # Override Thread constructor\n",
    "        super().__init__() # Call the parent constructor. Not optional because we are overriding __init__\n",
    "        self.id = id\n",
    "\n",
    "    def run(self): # Called \"run\" to comply with the Thread module default behavior.\n",
    "        print(f\"Task {self.id}: starting. \")\n",
    "        sleep(.1)\n",
    "        print(f\"Task {self.id}: finishing. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the ``run()`` method directly, we execute the code sequentially, as if ``Sleeper`` were not a ``Thread``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0: starting. \n",
      "Task 0: finishing. \n",
      "Task 1: starting. \n",
      "Task 1: finishing. \n",
      "Task 2: starting. \n",
      "Task 2: finishing. \n",
      "Task 3: starting. \n",
      "Task 3: finishing. \n",
      "Task 4: starting. \n",
      "Task 4: finishing. \n",
      "\n",
      "Time spent inside the loop: 0.5207247679999796 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter()\n",
    "\n",
    "for i in range(5):\n",
    "    Sleeper(i).run() # Not using threads\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to call the ``start()`` method inherited from ``Thread`` (see [https://docs.python.org/2/library/threading.html#thread-objects](https://docs.python.org/2/library/threading.html#thread-objects))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0: starting. \n",
      "Task 1: starting. \n",
      "Task 2: starting. Task 3: starting. Task 4: starting. \n",
      "\n",
      "\n",
      "Task 0: finishing. \n",
      "Task 1: finishing. Task 2: finishing. Task 3: finishing. Task 4: finishing. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Time spent inside the loop: 0.10441170199999306 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter()\n",
    "\n",
    "sleepers = list()\n",
    "for i in range(5):\n",
    "    sleepers.append(Sleeper(i))\n",
    "\n",
    "for sleeper in sleepers:\n",
    "    sleeper.start()\n",
    "\n",
    "for sleeper in sleepers:\n",
    "    sleeper.join()\n",
    "    \n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Locks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleeperLock(Sleeper): # SleeperLock is a Sleeper and thus a Thread\n",
    "    rlock = RLock() # This is a class variable. It is created only once.\n",
    "\n",
    "    def run(self): # Override the parent run() method\n",
    "        with self.rlock: \n",
    "            print(f\"Task {self.id}: starting. \")\n",
    "        sleep(.1)\n",
    "        with self.rlock: \n",
    "            print(f\"Task {self.id}: finishing. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0: starting. \n",
      "Task 1: starting. \n",
      "Task 2: starting. \n",
      "Task 3: starting. \n",
      "Task 4: starting. \n",
      "Task 0: finishing. \n",
      "Task 1: finishing. \n",
      "Task 3: finishing. \n",
      "Task 4: finishing. \n",
      "Task 2: finishing. \n",
      "\n",
      "Time spent inside the loop: 0.11455942500003857 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter()\n",
    "\n",
    "sleepers = list()\n",
    "for i in range(5):\n",
    "    sleepers.append(SleeperLock(i))\n",
    "\n",
    "for sleeper in sleepers:\n",
    "    sleeper.start()\n",
    "\n",
    "for sleeper in sleepers:\n",
    "    sleeper.join()\n",
    "    \n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes vs Threads, the GIL\n",
    "\n",
    "For performance reasons, and because of its age, Python uses a Global Interpreter Lock or GIL ([https://realpython.com/python-gil/](https://realpython.com/python-gil/)). This *lock* enforces the use of a single CPU core for pre-emptive and cooperative concurrency. If we want to leverage modern CPUs and their many cores, we need to turn to *multiprocessing* to run processes in *parallel*.\n",
    "\n",
    "**How to decide? It depends on your problem. Is it:**\n",
    "\n",
    "* I/O bound: use threading. The bottleneck is not your CPU, so running on more than one core is not going to improve performance.\n",
    "* CPU bound: use multiprocessing. If the problem maxes out one CPU core, chances are spreading the load is the solution.\n",
    "\n",
    "**Why not use multiprocessing all the time then?**\n",
    "\n",
    "Because it creates a lot of overhead by *spawning* or *forking* (see below) entire copies of your main python process whereas threads are much more lightweight and can share ressources between them in addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we start with the sequential baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time spent inside the loop: 5.4632731599999715 seconds.\n"
     ]
    }
   ],
   "source": [
    "from math import factorial\n",
    "\n",
    "it_nb = 30 # Change this to ajust compute time on your machine\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "for i in range(it_nb):\n",
    "    factorial(10**5) # Big number\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, just to be sure, using threading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time spent inside the loop: 5.578519464999999 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter()\n",
    "\n",
    "threads = list()\n",
    "\n",
    "for i in range(it_nb):\n",
    "    thread = Thread(target=factorial, args=(10**5,))\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the problem could use more **power**, not faster **I/O**. Let's check multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time spent inside the loop: 3.772360433000017 seconds.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "processes = list()\n",
    "\n",
    "for i in range(it_nb):\n",
    "    process = Process(target=factorial, args=(10**5,))\n",
    "    processes.append(process)\n",
    "\n",
    "for process in processes:\n",
    "    process.start()\n",
    "\n",
    "for process in processes:\n",
    "    process.join()\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a significant speedup in compute time if your computer has more than one core. But not quite as fast as the number of your computer cores would suggest. Why? The overhead of creating entire processes. Also, we created ``it_nb`` processes. Do you have that amount of CPU cores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores on my machine: 4\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "print(f\"Number of CPU cores on my machine: {cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map, Workers and Pools\n",
    "\n",
    "There are high-level tools to help you inject concurrency and parallelism into your code less painfully.\n",
    "\n",
    "One of the most handy tools is to think about your problem in relation to the ``map`` function ([https://realpython.com/python-map-function/](https://realpython.com/python-map-function/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time spent inside the loop: 5.51327655700004 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter()\n",
    "\n",
    "factorial_arguments = [10**5, ] * it_nb # [10**5, 10**5, ...]\n",
    "\n",
    "gen = map(factorial, factorial_arguments) # map is a generator (think yield)\n",
    "tuple(gen) # do the actual work\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the ``map`` version of the sequential code we saw above. Unsurprizingly, the execution time is similar.\n",
    "\n",
    "Let's see how to code it with threads. Even though we saw it would be useless in this CPU bound case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time spent inside the loop: 5.4734110069999815 seconds.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor \n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "with ThreadPoolExecutor() as pool: # Without arguments, ThreadPoolExecutor() will create as many workers as CPU cores + 4\n",
    "    tuple(pool.map(factorial, factorial_arguments))\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty neat and very limited code change. Note that ``ThreadPoolExecutor`` takes a ``max_workers`` argument so things don't get out of hand ([https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor))\n",
    "\n",
    "Now with multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time spent inside the loop: 2.979375985000047 seconds.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "with Pool() as pool: # Without arguments, Pool() will create as many workers as CPU cores (a good default).\n",
    "    tuple(pool.map(factorial, factorial_arguments))\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, minimal code change to add multiprocessing to your \"loop\".\n",
    "\n",
    "Note that all these ``map()`` functions have the added benefit of preserving order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 5, 1, 6, 2, 7, 3, 8, 4, 9, \n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import get_context, RLock\n",
    "\n",
    "rlock = RLock()\n",
    "\n",
    "def task(id):\n",
    "    with rlock:\n",
    "        if id < 10: # Only to keep the output small\n",
    "            print(id, end=', ')\n",
    "    return id\n",
    "\n",
    "with get_context(\"fork\").Pool() as pool: # get_context(\"fork\"). Seems necessary on my M1 mac, otherwise the code hangs. Try the normal Pool() first. \n",
    "    res = tuple(pool.map(task, range(71))) # Any number. May require a few tries to show different outputs.\n",
    "\n",
    "print()\n",
    "print(res[:10]) # the first 10 results should be sufficient to show the 2 lists are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are ordered even though the processes executed in a different order.\n",
    "\n",
    "**NB** for more explanations on *forks* and *spawns*:\n",
    "* [https://stackoverflow.com/questions/67999589/multiprocessing-with-pool-throws-error-on-m1-macbook](https://stackoverflow.com/questions/67999589/multiprocessing-with-pool-throws-error-on-m1-macbook)\n",
    "* [https://britishgeologicalsurvey.github.io/science/python-forking-vs-spawn](https://britishgeologicalsurvey.github.io/science/python-forking-vs-spawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of the number of workers on performance for multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 workers] Time spent inside the loop: 6.269686142999944 seconds.\n",
      "[2 workers] Time spent inside the loop: 3.629781209999919 seconds.\n",
      "[4 workers] Time spent inside the loop: 2.835050143999979 seconds.\n",
      "[8 workers] Time spent inside the loop: 2.9209445869998945 seconds.\n",
      "[16 workers] Time spent inside the loop: 3.2322444409999207 seconds.\n",
      "[32 workers] Time spent inside the loop: 3.8497500169999057 seconds.\n",
      "[64 workers] Time spent inside the loop: 5.136424924000039 seconds.\n",
      "[128 workers] Time spent inside the loop: 7.603548916999898 seconds.\n",
      "[256 workers] Time spent inside the loop: 13.032128056999909 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nh/_lkctsl16l393rkzcyztswd80000gn/T/ipykernel_2520/2016493663.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# We fix the number of workers ourselves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactorial_arguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/context.py\u001b[0m in \u001b[0;36mPool\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m'''Returns a process pool object'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         return Pool(processes, initializer, initargs, maxtasksperchild,\n\u001b[0m\u001b[1;32m    120\u001b[0m                     context=self.get_context())\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         return self._repopulate_pool_static(self._ctx, self.Process,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inqueue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool_static\u001b[0;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PoolWorker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'added worker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     56\u001b[0m                                          pipe_handle=child_r)\n\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchild_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             self.pid = util.spawnv_passfds(spawn.get_executable(),\n\u001b[0m\u001b[1;32m     59\u001b[0m                                            cmd, self._fds)\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/util.py\u001b[0m in \u001b[0;36mspawnv_passfds\u001b[0;34m(path, args, passfds)\u001b[0m\n\u001b[1;32m    455\u001b[0m             False, False, None, None, None, -1, None)\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "for i in range(10): \n",
    "    nb_workers = 2**i # Increase the number of workers exponentially\n",
    "\n",
    "    start_time = perf_counter()\n",
    "\n",
    "    with Pool(processes=nb_workers) as pool: # We fix the number of workers ourselves\n",
    "        tuple(pool.map(factorial, factorial_arguments))\n",
    "\n",
    "    print(f\"[{nb_workers} workers] Time spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is probably good enough to leave it to Python to determine the number of workers by calling your pools without arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "* [https://fastapi.tiangolo.com/async/#asynchronous-code](https://fastapi.tiangolo.com/async/#asynchronous-code)\n",
    "* [https://realpython.com/python-concurrency/](https://realpython.com/python-concurrency/)\n",
    "* [https://realpython.com/async-io-python/](https://realpython.com/async-io-python/)\n",
    "* [https://realpython.com/python-gil/](https://realpython.com/python-gil/)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "098abfbdda89cc068fc5a24c70b28519776b65016448753c248b3e3ae6b6b2c3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
